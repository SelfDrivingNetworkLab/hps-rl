*** Copyright Notice ***

HPS-RL: Hyperparameter tuning for deep RL applications (HPS-RL)
Copyright (c) 2022, The Regents of the University of California,
through Lawrence Berkeley National Laboratory (subject to receipt of
any required approvals from the U.S. Dept. of Energy), Oral Okyanus,
and Melis Ozyildirim. All rights reserved.

If you have questions about your rights to use or distribute this software,
please contact Berkeley Lab's Intellectual Property Office at
IPO@lbl.gov.

NOTICE.  This Software was developed under funding from the U.S. Department
of Energy and the U.S. Government consequently retains certain rights.  As
such, the U.S. Government has been granted for itself and others acting on
its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the
Software to reproduce, distribute copies to the public, prepare derivative 
works, and perform publicly and display publicly, and to permit others to do so.



# HPS-RL: Hyperparameter tuning for deep RL applications

Genetic Algorithms meets Deep RL for Hyperparameters
Hyperparameter optimization and architecture search can easily become cumbersome
and finding the right hyperparameters can seriously impact the robustness of the deep RL application being developed.

We use genetic algorithms to evolve optimum deep RL architectures in a scalable manner. 

HPS-RL is designed to work with multiple gym enviornments, allow users to test their own optimization functions and tune multi-objective parameters in multiple deep RL algorithms.
HPS-RL uses multi-threading and is being extended with mpipy for distributed processing on HPC.


## Documentation


## Explanations

## Install
Current installation of HPS-RL has been tested on Python 3.6.

## Example 

## Contact Us
